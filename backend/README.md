# ğŸ”§ Backend - Web Scraper AI API

Express.js backend service that scrapes websites and answers questions using Google Gemini AI.

## âœ¨ Features

- **ğŸŒ Web Scraping**
  - Playwright for JavaScript-heavy sites (local development)
  - Cheerio + Axios for static sites (production/lightweight)
  - Smart content extraction and cleaning

- **ğŸ¤– AI Integration**
  - Google Gemini 2.0 Flash for fast question answering
  - Context-aware responses based on scraped content
  - Configurable AI models and parameters

- **âš¡ Background Job Processing**
  - BullMQ for async task queue management
  - Redis-based job persistence
  - Automatic retry on failures
  - Real-time task status updates

- **ğŸ’¾ Data Management**
  - PostgreSQL database with Drizzle ORM
  - TypeScript schema definitions
  - Automatic migrations
  - Task history and tracking

- **ğŸ”’ Security & Validation**
  - URL validation and sanitization
  - Private IP address blocking
  - Content length limits
  - Input validation with error handling

- **ğŸ³ Docker Support**
  - Multi-stage production builds
  - Health checks and auto-restart
  - Optimized for containerized deployment

## ğŸ“ Directory Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                 # Express app entry point
â”‚   â”œâ”€â”€ controllers/             # Request handlers
â”‚   â”‚   â””â”€â”€ tasks.controller.ts  # Task CRUD operations
â”‚   â”œâ”€â”€ routes/                  # API route definitions
â”‚   â”‚   â””â”€â”€ tasks.route.ts       # Task endpoints
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ scraper.service.ts   # Web scraping (Playwright/Cheerio)
â”‚   â”‚   â””â”€â”€ ai.service.ts        # Gemini AI integration
â”‚   â”œâ”€â”€ queue/                   # Background job processing
â”‚   â”‚   â”œâ”€â”€ redis.ts             # Redis connection
â”‚   â”‚   â”œâ”€â”€ scrapeQueue.ts       # BullMQ queue setup
â”‚   â”‚   â””â”€â”€ scrapeWorker.ts      # Job processor
â”‚   â”œâ”€â”€ db/                      # Database layer
â”‚   â”‚   â”œâ”€â”€ index.ts             # Drizzle DB connection
â”‚   â”‚   â””â”€â”€ schema.ts            # Database schema (tasks table)
â”‚   â”œâ”€â”€ middleware/              # Express middleware
â”‚   â”‚   â””â”€â”€ errorHandler.ts     # Global error handling
â”‚   â””â”€â”€ types/                   # TypeScript definitions
â”‚       â””â”€â”€ index.ts             # Shared types
â”œâ”€â”€ drizzle/                     # Database migrations
â”‚   â”œâ”€â”€ 0000_tidy_preak.sql      # Initial schema
â”‚   â””â”€â”€ meta/                    # Migration metadata
â”œâ”€â”€ drizzle.config.ts            # Drizzle ORM configuration
â”œâ”€â”€ Dockerfile                   # Production Docker image
â”œâ”€â”€ docker-entrypoint.sh         # Startup script (runs migrations)
â”œâ”€â”€ .dockerignore                # Docker build exclusions
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ package.json                 # Dependencies & scripts
â”œâ”€â”€ tsconfig.json                # TypeScript configuration
â””â”€â”€ README.md                    # This file
```

## ğŸ”‘ Key Technologies

- **Runtime**: Node.js 20 with TypeScript
- **Framework**: Express.js
- **Database**: PostgreSQL 16 with Drizzle ORM
- **Cache/Queue**: Redis 7 with BullMQ
- **AI**: Google Gemini API (@google/generative-ai)
- **Scraping**: Playwright (dev) / Axios + Cheerio (prod)
- **Validation**: Zod for schema validation

## ğŸŒ API Endpoints

### Route Structure

```
/
â”œâ”€â”€ /health                      # Health check
â””â”€â”€ /api
    â””â”€â”€ /tasks
        â”œâ”€â”€ POST   /             # Create new task
        â”œâ”€â”€ GET    /             # List all tasks (with pagination)
        â””â”€â”€ GET    /:id          # Get specific task by ID
```

### **POST** `/api/tasks`
Create a new scraping task

**Request Body:**
```json
{
  "url": "https://example.com",
  "question": "What is this website about?"
}
```

**Response:**
```json
{
  "id": 1,
  "url": "https://example.com",
  "question": "What is this website about?",
  "status": "pending",
  "createdAt": "2025-11-15T10:00:00.000Z"
}
```

### **GET** `/api/tasks`
List all tasks with pagination

**Query Parameters:**
- `limit` (optional) - Number of results per page (default: 10)
- `offset` (optional) - Number of results to skip (default: 0)

**Response:**
```json
{
  "tasks": [
    {
      "id": 1,
      "url": "https://example.com",
      "question": "What is this website about?",
      "status": "completed",
      "aiAnswer": "This website is about...",
      "createdAt": "2025-11-15T10:00:00.000Z",
      "completedAt": "2025-11-15T10:00:30.000Z"
    }
  ],
  "total": 1
}
```

### **GET** `/api/tasks/:id`
Get specific task details with AI answer

**Response:**
```json
{
  "id": 1,
  "url": "https://example.com",
  "question": "What is this website about?",
  "status": "completed",
  "scrapedContent": "Full website content...",
  "aiAnswer": "This website is about...",
  "createdAt": "2025-11-15T10:00:00.000Z",
  "updatedAt": "2025-11-15T10:00:30.000Z",
  "completedAt": "2025-11-15T10:00:30.000Z"
}
```

### **GET** `/health`
Health check endpoint

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2025-11-15T10:00:00.000Z",
  "uptime": 3600
}
```

## ğŸš€ Getting Started

See the main [README.md](../README.md) in the root directory for setup instructions.

**Quick Start:**
```bash
# Install dependencies
npm install

# Setup environment
cp .env.example .env
# Edit .env with your configuration

# Run migrations
npm run db:push

# Start development server
npm run dev
```

## ğŸ“ Environment Variables

See `.env.example` for all configuration options including:
- `DATABASE_URL` - PostgreSQL connection string
- `REDIS_HOST` / `REDIS_PORT` - Redis connection
- `GEMINI_API_KEY` - Google AI Studio API key
- `USE_PLAYWRIGHT` - Toggle between Playwright/Cheerio
- `MAX_CONTENT_LENGTH` - Content extraction limit

## ğŸ”„ How It Works

1. **User submits task** â†’ POST `/api/tasks` with URL and question
2. **Task created** â†’ Saved to PostgreSQL with status "pending"
3. **Job queued** â†’ Task added to BullMQ queue for background processing
4. **Worker processes** â†’ Scrapes website, sends to Gemini AI, saves answer
5. **User polls** â†’ GET `/api/tasks/:id` to check status and get result
6. **Complete** â†’ Task status updated to "completed" with AI answer

## ğŸ“Š Database Schema

**tasks** table:
- `id` - Auto-increment primary key
- `url` - Website URL to scrape
- `question` - User's question
- `status` - pending | processing | completed | failed
- `scrapedContent` - Extracted website text
- `aiAnswer` - Gemini AI response
- `errorMessage` - Error details if failed
- `createdAt` - Timestamp
- `updatedAt` - Last update timestamp
- `completedAt` - Completion timestamp

## ğŸ› Troubleshooting

**Database connection issues:**
- Ensure PostgreSQL is running
- Check `DATABASE_URL` in `.env`
- For local dev, use `localhost` not `postgres`

**Redis connection errors:**
- Verify Redis is running
- Check `REDIS_HOST` in `.env`
- For local dev, use `localhost` not `redis`

**Scraping failures:**
- Check if website blocks bots
- Try enabling Playwright: `USE_PLAYWRIGHT=true`
- Verify website is accessible
